{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f644c055710>"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1,2,1],\n",
    "                             [1,3,2],\n",
    "                             [1,3,4],\n",
    "                             [1,5,5],\n",
    "                             [1,7,5],\n",
    "                             [1,2,5],\n",
    "                             [1,6,6],\n",
    "                             [1,7,7]])\n",
    "y_train = torch.LongTensor([2,2,2,1,1,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.FloatTensor([[2,1,1],[3,1,2],[3,3,4]])\n",
    "y_test = torch.LongTensor([2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,3)    # softmax 이므로 output도 3\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "    for epoch in range(nb_epochs):\n",
    "\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        cost = F.cross_entropy(prediction,y_train)  # cross_entropy는 classification\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, optimzer, x_test, y_test):\n",
    "    prediction = model(x_test)\n",
    "    predicted_classes = prediction.max(1)[1]\n",
    "    correct_count = (predicted_classes == y_test).sum().item()\n",
    "    cost = F.cross_entropy(prediction, y_test)\n",
    "\n",
    "    print('Accuracy: {}% Cost: {:.6f}'.format(\n",
    "        correct_count / len(y_test) * 100, cost.item()\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/20 Cost: 1.280268\nEpoch    1/20 Cost: 1.007498\nEpoch    2/20 Cost: 0.999968\nEpoch    3/20 Cost: 0.992704\nEpoch    4/20 Cost: 0.985657\nEpoch    5/20 Cost: 0.978815\nEpoch    6/20 Cost: 0.972169\nEpoch    7/20 Cost: 0.965709\nEpoch    8/20 Cost: 0.959425\nEpoch    9/20 Cost: 0.953312\nEpoch   10/20 Cost: 0.947360\nEpoch   11/20 Cost: 0.941562\nEpoch   12/20 Cost: 0.935913\nEpoch   13/20 Cost: 0.930405\nEpoch   14/20 Cost: 0.925033\nEpoch   15/20 Cost: 0.919792\nEpoch   16/20 Cost: 0.914675\nEpoch   17/20 Cost: 0.909678\nEpoch   18/20 Cost: 0.904796\nEpoch   19/20 Cost: 0.900025\n"
     ]
    }
   ],
   "source": [
    "train(model,optimizer,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 100.0% Cost: 0.390032\n"
     ]
    }
   ],
   "source": [
    "test(model,optimizer,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73,80,75],\n",
    "                                              [93,88,93],\n",
    "                                              [89,91,90],\n",
    "                                              [96,98,100],\n",
    "                                              [73,66,70]])\n",
    "y_train = torch.FloatTensor([[152],[185],[180],[196],[142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = x_train.mean(dim=0)\n",
    "sigma = x_train.std(dim=0)\n",
    "norm_x_train = (x_train - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-1.0674, -0.3758, -0.8398],\n        [ 0.7418,  0.2778,  0.5863],\n        [ 0.3799,  0.5229,  0.3486],\n        [ 1.0132,  1.0948,  1.1409],\n        [-1.0674, -1.5197, -1.2360]])\n"
     ]
    }
   ],
   "source": [
    "print(norm_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimzaer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "    for epoch in range(nb_epochs):\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch+1, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    1/20 Cost: 4.379876\nEpoch    2/20 Cost: 2.970576\nEpoch    3/20 Cost: 2.063685\nEpoch    4/20 Cost: 1.478584\nEpoch    5/20 Cost: 1.099592\nEpoch    6/20 Cost: 0.852663\nEpoch    7/20 Cost: 0.690433\nEpoch    8/20 Cost: 0.582564\nEpoch    9/20 Cost: 0.509645\nEpoch   10/20 Cost: 0.459253\nEpoch   11/20 Cost: 0.423391\nEpoch   12/20 Cost: 0.396987\nEpoch   13/20 Cost: 0.376754\nEpoch   14/20 Cost: 0.360606\nEpoch   15/20 Cost: 0.347198\nEpoch   16/20 Cost: 0.335655\nEpoch   17/20 Cost: 0.325406\nEpoch   18/20 Cost: 0.316109\nEpoch   19/20 Cost: 0.307519\nEpoch   20/20 Cost: 0.299481\n"
     ]
    }
   ],
   "source": [
    "train(model,optimizer,norm_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_regularization(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "    for epoch in range(nb_epochs):\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        l2_reg = 0\n",
    "        for param in model.parameters():\n",
    "            l2_reg = torch.norm(param)\n",
    "\n",
    "        cost += l2_reg  # 특정 parameter가 너무 커지는 것을 방지시킴\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch+1, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    1/20 Cost: 29477.394531\nEpoch    2/20 Cost: 18780.335938\nEpoch    3/20 Cost: 12038.477539\nEpoch    4/20 Cost: 7754.027832\nEpoch    5/20 Cost: 5020.800781\nEpoch    6/20 Cost: 3274.093994\nEpoch    7/20 Cost: 2156.937500\nEpoch    8/20 Cost: 1442.163208\nEpoch    9/20 Cost: 984.759644\nEpoch   10/20 Cost: 692.028931\nEpoch   11/20 Cost: 504.675903\nEpoch   12/20 Cost: 384.761047\nEpoch   13/20 Cost: 308.006287\nEpoch   14/20 Cost: 258.873596\nEpoch   15/20 Cost: 227.419510\nEpoch   16/20 Cost: 207.280212\nEpoch   17/20 Cost: 194.382584\nEpoch   18/20 Cost: 186.120026\nEpoch   19/20 Cost: 180.824127\nEpoch   20/20 Cost: 177.427139\n"
     ]
    }
   ],
   "source": [
    "train_with_regularization(model,optimizer,norm_x_train,y_train)"
   ]
  }
 ]
}